Trên đây là kết quả nghiên cứu mới được công bố , trong đó nhấn mạnh những điều này xảy ra kể cả khi các công ty đều đã có những chính sách để ngăn chặn thông tin sai lệch .
Nghiên cứu do Trung tâm chống thông tin thù hận trên mạng ( CCDH ) thực hiện , trong đó kiểm tra khả năng của các công cụ AI tạo sinh trong việc chặn các câu lệnh yêu cầu tạo ra những hình ảnh không có thực như Tổng thống Mỹ Joe Biden nằm viện hay các nhân viên phục vụ bầu cử đập thùng phiếu .
Các ứng dụng được kiểm tra bao gồm ChatGPT Plus của OpenAI , Image Creator của Microsoft , DreamStudio của Stability AI và ứng dụng Midjourney . Kết quả cho thấy trung bình có 41 % các cuộc kiểm tra vẫn sáng tạo ra hình ảnh theo câu lệnh có liên quan gian lận bầu cử ; các ứng dụng cũng tỏ ra nhạy bén nhất với những câu lệnh yêu cầu những hình ảnh mô tả gian lận bầu cử , ví dụ như thùng phiếu bị vứt bỏ , hơn là những yêu cầu liên quan đến cựu Tổng thống Donald Trump và đương kim Tổng thống Joe Biden .
Trong các cuộc kiểm tra này , ChatGPT Plus và Image Creator đã thành công trong việc ngăn chặn các câu lệnh yêu cầu hình ảnh các ứng cử viên . Trong khi đó , Midjourney có kết quả thấp nhất , với 65 % các lần kiểm tra đều tạo ra những hình ảnh gây hiểu nhầm . Một số hình ảnh do công cụ này sáng tạo đã được công bố tới người dùng và có bằng chứng cho thấy công cụ này đã được sử dụng để tạo ra những nội dung chính trị sai lệch .
Theo nghiên cứu , sẽ rất nguy hiểm khi những hình ảnh do AI sáng tạo được dùng để minh họa cho các thông tin giả , sai lệch về bầu cử . Điều này sẽ gây ra thách thức đáng kể trong bảo vệ tính trung thực trong các cuộc bầu cử . Tháng trước , một nhóm 20 công ty công nghệ trong đó có OpenAI , Microsoft và Stability AI đã ký kết một thỏa thuận phối hợp để ngăn chặn những nội dung gây hiểu nhầm do AI sáng tạo tác động đến các cuộc bầu cử sắp diễn ra trên toàn cầu .
Về vấn đề này , nhà sáng lập Midjourney , David Holz , cho biết công ty sẽ sớm thực hiện các cập nhật cần thiết đặc biệt liên quan tới cuộc bầu cử sắp tới tại Mỹ . Những hình ảnh gây hiểu nhầm đã được tạo ra từ năm ngoái và những thông lệ hiện nay của công ty đã khác . Người phát ngôn của Stability AI cho biết công ty này đã cập nhật chính sách từ cuối tuần trước để ngăn chặn những thông tin sai lệch . Tương tự , OpenAI cũng cho biết đang nỗ lực ngăn chặn tình trạng lạm dụng công cụ của công ty . Microsoft chưa có phản hồi về nghiên cứu kể trên .

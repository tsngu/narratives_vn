Trên đây là kết_quả nghiên_cứu mới được công_bố , trong đó nhấn_mạnh những điều này xảy ra kể_cả khi các công_ty đều đã có những chính_sách để ngăn_chặn thông_tin sai_lệch .
Nghiên_cứu do Trung_tâm chống thông_tin thù_hận trên mạng ( CCDH ) thực_hiện , trong đó kiểm_tra khả_năng của các công_cụ AI tạo sinh trong việc chặn các câu_lệnh yêu_cầu tạo ra những hình_ảnh không có thực như Tổng_thống Mỹ Joe Biden nằm viện hay các nhân_viên phục_vụ bầu_cử đập thùng phiếu .
Các ứng_dụng được kiểm_tra bao_gồm ChatGPT Plus của OpenAI , Image_Creator của Microsoft , DreamStudio của Stability AI và ứng_dụng Midjourney . Kết_quả cho thấy trung_bình có 41 % các cuộc kiểm_tra vẫn sáng_tạo ra hình_ảnh theo câu_lệnh có liên_quan gian_lận bầu_cử ; các ứng_dụng cũng tỏ ra nhạy_bén nhất với những câu_lệnh yêu_cầu những hình_ảnh mô_tả gian_lận bầu_cử , ví_dụ như thùng phiếu bị vứt bỏ , hơn là những yêu_cầu liên_quan đến cựu Tổng_thống Donald_Trump và đương_kim Tổng_thống Joe_Biden .
Trong các cuộc kiểm_tra này , ChatGPT Plus và Image_Creator đã thành_công trong việc ngăn_chặn các câu_lệnh yêu_cầu hình_ảnh các ứng_cử_viên . Trong khi đó , Midjourney có kết_quả thấp nhất , với 65 % các lần kiểm_tra đều tạo ra những hình_ảnh gây hiểu nhầm . Một_số hình_ảnh do công_cụ này sáng_tạo đã được công_bố tới người dùng và có bằng_chứng cho thấy công_cụ này đã được sử_dụng để tạo ra những nội_dung chính_trị sai_lệch .
Theo nghiên_cứu , sẽ rất nguy_hiểm khi những hình_ảnh do AI sáng_tạo được dùng để minh_họa cho các thông_tin giả , sai_lệch về bầu_cử . Điều này sẽ gây ra thách_thức đáng_kể trong bảo_vệ tính trung_thực trong các cuộc bầu_cử . Tháng trước , một nhóm 20 công_ty công_nghệ trong đó có OpenAI , Microsoft và Stability AI đã ký_kết một thỏa_thuận phối_hợp để ngăn_chặn những nội_dung gây hiểu nhầm do AI sáng_tạo tác_động đến các cuộc bầu_cử sắp diễn ra trên toàn_cầu .
Về vấn_đề này , nhà sáng_lập Midjourney , David_Holz , cho biết công_ty sẽ sớm thực_hiện các cập_nhật cần_thiết đặc_biệt liên_quan tới cuộc bầu_cử sắp tới tại Mỹ . Những hình_ảnh gây hiểu nhầm đã được tạo ra từ năm_ngoái và những thông_lệ hiện_nay của công_ty đã khác . Người_phát_ngôn của Stability AI cho biết công_ty này đã cập_nhật chính_sách từ cuối tuần trước để ngăn_chặn những thông_tin sai_lệch . Tương_tự , OpenAI cũng cho biết đang nỗ_lực ngăn_chặn tình_trạng lạm_dụng công_cụ của công_ty . Microsoft chưa có phản_hồi về nghiên_cứu kể trên .
